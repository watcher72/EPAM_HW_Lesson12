{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Student: Kiseleva Elena_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# display all outputs, not only last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. К каждому элементу списка применить какуе-либо преобразование (например, для числового списка - возвести в кавдрат, для строкового - привести к верхнему регистру, отфильтровать определенные символы, и т.д.).\n",
    "\n",
    "_Проверим приведение строковых элементов списка к верхнему регистру четырьмя способами: с помощью функции map, с помощью генератора, с помощью List comprehension и через обычный цикл for._\n",
    "Для начала пусть результат работы функции map и генератора возвращаются в виде map-объекта и объекта-генератора. Ра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./mapping/mapping_list.py\n",
    "import random\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "\n",
    "ABC = 'abcdefghijklmnopqrstufwxyzABCDEFGHIJKLMNOPQRSTUFWXYZ'\n",
    "\n",
    "\n",
    "def prepare_data(letters, words):\n",
    "    return [''.join(random.sample(ABC, letters)) for _ in range(words)]\n",
    "\n",
    "\n",
    "def to_upper_v1(data):\n",
    "    return map(lambda x: x.upper(), data)\n",
    "\n",
    "\n",
    "def to_upper_v2(data):\n",
    "    return (word.upper() for word in data)\n",
    "\n",
    "\n",
    "def to_upper_v3(data):\n",
    "    return [word.upper() for word in data]\n",
    "\n",
    "\n",
    "def to_upper_v4(data):\n",
    "    result = []\n",
    "    for word in data:\n",
    "        result.append(word.upper())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./mapping/test_mapping_list.py\n",
    "from mapping.mapping_list import to_upper_v1, to_upper_v2, to_upper_v3, to_upper_v4\n",
    "\n",
    "\n",
    "def test_to_upper_v1():\n",
    "    actual = list(to_upper_v1(['abc', 'deFgH', 'ijKL']))\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "def test_to_upper_v2():\n",
    "    actual = list(to_upper_v2(['abc', 'deFgH', 'ijKL']))\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "    \n",
    "def test_to_upper_v3():\n",
    "    actual = to_upper_v3(['abc', 'deFgH', 'ijKL'])\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "def test_to_upper_v4():\n",
    "    actual = to_upper_v4(['abc', 'deFgH', 'ijKL'])\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.4, pytest-5.4.3, py-1.9.0, pluggy-0.13.1 -- F:\\!EPAM\\HW_Lesson12\\venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: F:\\!EPAM\\HW_Lesson12\n",
      "collecting ... collected 4 items\n",
      "\n",
      "mapping/test_mapping_list.py::test_to_upper_v1 PASSED                    [ 25%]\n",
      "mapping/test_mapping_list.py::test_to_upper_v2 PASSED                    [ 50%]\n",
      "mapping/test_mapping_list.py::test_to_upper_v3 PASSED                    [ 75%]\n",
      "mapping/test_mapping_list.py::test_to_upper_v4 PASSED                    [100%]\n",
      "\n",
      "============================== 4 passed in 0.09s ==============================\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest -v ./mapping/test_mapping_list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(24, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First version (with map-function):\n",
      "687 ns ± 65.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "\n",
      "Second version (with generator):\n",
      "1.14 µs ± 259 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "\n",
      "Third version (with list comprehansion):\n",
      "2.39 ms ± 391 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "\n",
      "Fourth version (with for-loop):\n",
      "5.15 ms ± 1.03 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "print('First version (with map-function):')\n",
    "%timeit to_upper_v1(data)\n",
    "print('\\nSecond version (with generator):')\n",
    "%timeit to_upper_v2(data)\n",
    "print('\\nThird version (with list comprehansion):')\n",
    "%timeit to_upper_v3(data)\n",
    "print('\\nFourth version (with for-loop):')\n",
    "%timeit to_upper_v4(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         30006004 function calls in 14.496 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     1000    5.290    0.005    8.794    0.009 mapping_list.py:25(to_upper_v4)\n",
      " 20000000    4.125    0.000    4.125    0.000 {method 'upper' of 'str' objects}\n",
      "     1000    3.043    0.003    4.979    0.005 mapping_list.py:22(<listcomp>)\n",
      " 10000000    1.314    0.000    1.314    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.713    0.713   14.496   14.496 <ipython-input-8-6760ac1f87d9>:5(benchmark)\n",
      "     1000    0.005    0.000    0.005    0.000 mapping_list.py:13(to_upper_v1)\n",
      "     1000    0.003    0.000    4.982    0.005 mapping_list.py:21(to_upper_v3)\n",
      "     1000    0.002    0.000    0.002    0.000 mapping_list.py:17(to_upper_v2)\n",
      "     1000    0.001    0.000    0.001    0.000 mapping_list.py:18(<genexpr>)\n",
      "        1    0.000    0.000   14.496   14.496 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   14.496   14.496 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "\n",
    "data = prepare_data(24, 10000)\n",
    "\n",
    "def benchmark(n):\n",
    "    for i in range(n):\n",
    "        to_upper_v1(data)\n",
    "        to_upper_v2(data)\n",
    "        to_upper_v3(data)\n",
    "        to_upper_v4(data)\n",
    "\n",
    "\n",
    "cProfile.run('benchmark(1000)', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark benchmark(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 0.0191766 s\n",
    "File: <ipython-input-8-6760ac1f87d9>\n",
    "Function: benchmark at line 5\n",
    "\n",
    "Line       Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     5                                           def benchmark(n):\n",
    "     6         2        164.0     82.0      0.1      for i in range(n):\n",
    "     7         1        112.0    112.0      0.1          to_upper_v1(data)\n",
    "     8         1        110.0    110.0      0.1          to_upper_v2(data)\n",
    "     9         1      60312.0  60312.0     31.5          to_upper_v3(data)\n",
    "    10         1     131068.0 131068.0     68.3          to_upper_v4(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mapping_list_memory_profiling.py\n",
    "from memory_profiler import profile\n",
    "\n",
    "from mapping.mapping_list import to_upper_v1, to_upper_v2, to_upper_v3, to_upper_v4, prepare_data\n",
    "\n",
    "\n",
    "@profile\n",
    "def run_all():\n",
    "    data = prepare_data(24, 10000)\n",
    "    result1 = to_upper_v1(data)\n",
    "    result2 = to_upper_v2(data)\n",
    "    result3 = to_upper_v3(data)\n",
    "    result4 = to_upper_v4(data)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: mapping_list_memory_profiling.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "     6     14.2 MiB     14.2 MiB   @profile\n",
      "     7                             def run_all():\n",
      "     8     14.8 MiB      0.6 MiB       data = prepare_data(24, 10000)\n",
      "     9     14.8 MiB      0.0 MiB       result1 = to_upper_v1(data)\n",
      "    10     14.8 MiB      0.0 MiB       result2 = to_upper_v2(data)\n",
      "    11     15.4 MiB      0.6 MiB       result3 = to_upper_v3(data)\n",
      "    12     16.0 MiB      0.6 MiB       result4 = to_upper_v4(data)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python mapping_list_memory_profiling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если результат работы функций `to_upper_v1` и `to_upper_v2` нужно использовать для дальнейшей обработки в виде итерируемого объекта, то можно возвращать не собственно список, а генератор или map-объект, тогда получаем и значительный выигрыш по быстродействию (ведь фактически из-за \"ленивости\" генератора и map-объекта вычисления именно в момент вызова функции не производятся, они будут производится позже, по мере необходимости), и по экономии памяти. Хуже всего работает чистый цикл `for` (очевидно, из-за того, что в каждой итерации происходит обращение к памяти для добавления в список нового элемента)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Попробуем изменить первые две функции, чтобы они тоже возвращали список.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper_v1_to_list(data):\n",
    "    return list(map(lambda x: x.upper(), data))\n",
    "\n",
    "\n",
    "def to_upper_v2_to_list(data):\n",
    "    return list(word.upper() for word in data)\n",
    "\n",
    "\n",
    "def to_upper_v3(data):\n",
    "    return [word.upper() for word in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 ms ± 979 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3.94 ms ± 908 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.63 ms ± 418 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit to_upper_v1_to_list(data)\n",
    "%timeit to_upper_v2_to_list(data)\n",
    "%timeit to_upper_v3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         50005004 function calls in 22.091 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 30000000    6.210    0.000    6.210    0.000 {method 'upper' of 'str' objects}\n",
      " 10001000    3.875    0.000    5.946    0.000 <ipython-input-21-e7cff83ef4ef>:6(<genexpr>)\n",
      " 10000000    3.310    0.000    5.454    0.000 <ipython-input-21-e7cff83ef4ef>:2(<lambda>)\n",
      "     1000    2.783    0.003    4.777    0.005 <ipython-input-21-e7cff83ef4ef>:10(<listcomp>)\n",
      "     1000    2.763    0.003    8.217    0.008 <ipython-input-21-e7cff83ef4ef>:1(to_upper_v1_to_list)\n",
      "     1000    1.778    0.002    7.724    0.008 <ipython-input-21-e7cff83ef4ef>:5(to_upper_v2_to_list)\n",
      "        1    1.368    1.368   22.091   22.091 <ipython-input-23-3abed70fe950>:3(benchmark_2)\n",
      "     1000    0.005    0.000    4.782    0.005 <ipython-input-21-e7cff83ef4ef>:9(to_upper_v3)\n",
      "        1    0.000    0.000   22.091   22.091 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   22.091   22.091 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(24, 10000)\n",
    "\n",
    "def benchmark_2(n):\n",
    "    for i in range(n):\n",
    "        to_upper_v1_to_list(data)\n",
    "        to_upper_v2_to_list(data)\n",
    "        to_upper_v3(data)\n",
    "\n",
    "\n",
    "cProfile.run('benchmark_2(1000)', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark_2 benchmark_2(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 0.0317928 s\n",
    "File: <ipython-input-23-3abed70fe950>\n",
    "Function: benchmark_2 at line 3\n",
    "\n",
    "Line  #     Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     3                                           def benchmark_2(n):\n",
    "     4         2         94.0     47.0      0.0      for i in range(n):\n",
    "     5         1     110786.0 110786.0     34.8          to_upper_v1_to_list(data)\n",
    "     6         1     130160.0 130160.0     40.9          to_upper_v2_to_list(data)\n",
    "     7         1      76888.0  76888.0     24.2          to_upper_v3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mapping_list_memory_profiling_2.py\n",
    "from memory_profiler import profile\n",
    "\n",
    "from mapping.mapping_list_2 import to_upper_v1_to_list, to_upper_v2_to_list, to_upper_v3, to_upper_v4, prepare_data\n",
    "\n",
    "\n",
    "@profile\n",
    "def run_all():\n",
    "    data = prepare_data(24, 10000)\n",
    "    result1 = to_upper_v1_to_list(data)\n",
    "    result2 = to_upper_v2_to_list(data)\n",
    "    result3 = to_upper_v3(data)\n",
    "    result4 = to_upper_v4(data)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: mapping_list_memory_profiling_2.py\n",
      "\n",
      "Line #    Mem usage    Increment   Line Contents\n",
      "================================================\n",
      "     6     14.2 MiB     14.2 MiB   @profile\n",
      "     7                             def run_all():\n",
      "     8     14.8 MiB      0.6 MiB       data = prepare_data(24, 10000)\n",
      "     9     15.5 MiB      0.6 MiB       result1 = to_upper_v1_to_list(data)\n",
      "    10     16.1 MiB      0.6 MiB       result2 = to_upper_v2_to_list(data)\n",
      "    11     16.6 MiB      0.5 MiB       result3 = to_upper_v3(data)\n",
      "    12     17.3 MiB      0.7 MiB       result4 = to_upper_v4(data)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python mapping_list_memory_profiling_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, получаем, что операция преобразования генератора в список \"съедает\" практически весь выигрыш от его \"ленивости\", и он работает даже медленнее, чем list comprehension.\n",
    "\n",
    "В целом, выигрыш от функции map или генератора будет ощутим, если результаты его работы будут передаваться для дальнейшей обработки в виде итератора. При этом если в итоге будут обработаны все элементы списка, то мы получим лишь выигрыш по памяти, поскольку время на их обработку может оказаться даже больше, чем при использовании list comprehension (возможно, за счет дополнительных операций по созданию самого генератора и работы с элементами списка через него)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
