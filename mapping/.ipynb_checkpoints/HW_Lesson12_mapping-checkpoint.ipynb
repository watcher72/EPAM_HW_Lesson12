{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# display all outputs, not only last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mapping_list.py\n",
    "import random\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "\n",
    "ABC = 'abcdefghijklmnopqrstufwxyzABCDEFGHIJKLMNOPQRSTUFWXYZ'\n",
    "\n",
    "\n",
    "def prepare_data(letters, words):\n",
    "    return [''.join(random.sample(ABC, letters)) for _ in range(words)]\n",
    "\n",
    "\n",
    "def to_upper_v1(data):\n",
    "    return map(lambda x: x.upper(), data)\n",
    "\n",
    "\n",
    "def to_upper_v2(data):\n",
    "    return (word.upper() for word in data)\n",
    "\n",
    "\n",
    "def to_upper_v3(data):\n",
    "    return [word.upper() for word in data]\n",
    "\n",
    "\n",
    "def to_upper_v4(data):\n",
    "    result = []\n",
    "    for word in data:\n",
    "        result.append(word.upper())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load test_mapping_list.py\n",
    "from mapping.mapping_list import to_upper_v1, to_upper_v2, to_upper_v3, to_upper_v4\n",
    "\n",
    "\n",
    "def test_to_upper_v1():\n",
    "    actual = list(to_upper_v1(['abc', 'deFgH', 'ijKL']))\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "def test_to_upper_v2():\n",
    "    actual = list(to_upper_v2(['abc', 'deFgH', 'ijKL']))\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "    \n",
    "def test_to_upper_v3():\n",
    "    actual = to_upper_v3(['abc', 'deFgH', 'ijKL'])\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n",
    "\n",
    "\n",
    "def test_to_upper_v4():\n",
    "    actual = to_upper_v4(['abc', 'deFgH', 'ijKL'])\n",
    "    expected = ['ABC', 'DEFGH', 'IJKL']\n",
    "    assert actual == expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= test session starts =============================\n",
      "platform win32 -- Python 3.7.4, pytest-5.4.3, py-1.9.0, pluggy-0.13.1 -- F:\\!EPAM\\HW_Lesson12\\venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: F:\\!EPAM\\HW_Lesson12\\mapping\n",
      "collecting ... collected 0 items / 1 error\n",
      "\n",
      "=================================== ERRORS ====================================\n",
      "____________________ ERROR collecting test_mapping_list.py ____________________\n",
      "ImportError while importing test module 'F:\\!EPAM\\HW_Lesson12\\mapping\\test_mapping_list.py'.\n",
      "Hint: make sure your test modules/packages have valid Python names.\n",
      "Traceback:\n",
      "test_mapping_list.py:1: in <module>\n",
      "    from mapping.mapping_list import to_upper_v1, to_upper_v2, to_upper_v3, to_upper_v4\n",
      "E   ModuleNotFoundError: No module named 'mapping'\n",
      "=========================== short test summary info ===========================\n",
      "ERROR test_mapping_list.py\n",
      "!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "============================== 1 error in 0.23s ===============================\n"
     ]
    }
   ],
   "source": [
    "!python -m pytest -v test_mapping_list.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(24, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First version (with map-function):')\n",
    "%timeit to_upper_v1(data)\n",
    "print('\\nSecond version (with generator):')\n",
    "%timeit to_upper_v2(data)\n",
    "print('\\nThird version (with list comprehansion):')\n",
    "%timeit to_upper_v3(data)\n",
    "print('\\nFourth version (with for-loop):')\n",
    "%timeit to_upper_v4(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "\n",
    "data = prepare_data(24, 10000)\n",
    "\n",
    "def benchmark(n):\n",
    "    for i in range(n):\n",
    "        to_upper_v1(data)\n",
    "        to_upper_v2(data)\n",
    "        to_upper_v3(data)\n",
    "        to_upper_v4(data)\n",
    "\n",
    "\n",
    "cProfile.run('benchmark(1000)', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark benchmark(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 0.0164431 s\n",
    "File: <ipython-input-8-6760ac1f87d9>\n",
    "Function: benchmark at line 5\n",
    "\n",
    "Line       Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     5                                           def benchmark(n):\n",
    "     6         2        121.0     60.5      0.1      for i in range(n):\n",
    "     7         1         78.0     78.0      0.0          to_upper_v1(data)\n",
    "     8         1         71.0     71.0      0.0          to_upper_v2(data)\n",
    "     9         1      60037.0  60037.0     36.5          to_upper_v3(data)\n",
    "    10         1     104124.0 104124.0     63.3          to_upper_v4(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load mapping_list_memory_profiling.py\n",
    "from memory_profiler import profile\n",
    "\n",
    "from mapping_list import to_upper_v1, to_upper_v2, to_upper_v3, to_upper_v4, prepare_data\n",
    "\n",
    "\n",
    "@profile\n",
    "def run_all():\n",
    "    data = prepare_data(24, 10000)\n",
    "    result1 = to_upper_v1(data)\n",
    "    result2 = to_upper_v2(data)\n",
    "    result3 = to_upper_v3(data)\n",
    "    result4 = to_upper_v4(data)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mapping_list_memory_profiling.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если результат работы функций `to_upper_v1` и `to_upper_v2` нужно использовать для дальнейшей обработки в виде итерируемого объекта, то можно возвращать не собственно список, а генератор или map-объект, тогда получаем и значительный выигрыш по быстродействию (ведь фактически из-за \"ленивости\" генератора и map-объекта вычисления именно в момент вызова функции не производятся, они будут производится позже, по мере необходимости), и по экономии памяти. Хуже всего работает чистый цикл `for` (очевидно, из-за того, что в каждой итерации происходит обращение к памяти для добавления в список нового элемента)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Попробуем изменить первые две функции, чтобы они тоже возвращали список.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper_v1_to_list(data):\n",
    "    return list(map(lambda x: x.upper(), data))\n",
    "\n",
    "\n",
    "def to_upper_v2_to_list(data):\n",
    "    return list(word.upper() for word in data)\n",
    "\n",
    "\n",
    "def to_upper_v3(data):\n",
    "    return [word.upper() for word in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit to_upper_v1_to_list(data)\n",
    "%timeit to_upper_v2_to_list(data)\n",
    "%timeit to_upper_v3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(24, 10000)\n",
    "\n",
    "def benchmark_2(n):\n",
    "    for i in range(n):\n",
    "        to_upper_v1_to_list(data)\n",
    "        to_upper_v2_to_list(data)\n",
    "        to_upper_v3(data)\n",
    "\n",
    "\n",
    "cProfile.run('benchmark_2(1000)', sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark_2 benchmark_2(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 0.0215237 s\n",
    "File: <ipython-input-17-3abed70fe950>\n",
    "Function: benchmark_2 at line 3\n",
    "\n",
    "Line       Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     3                                           def benchmark_2(n):\n",
    "     4         2         87.0     43.5      0.0      for i in range(n):\n",
    "     5         1      86059.0  86059.0     40.0          to_upper_v1_to_list(data)\n",
    "     6         1      70513.0  70513.0     32.8          to_upper_v2_to_list(data)\n",
    "     7         1      58578.0  58578.0     27.2          to_upper_v3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mapping_list_memory_profiling_2.py\n",
    "from memory_profiler import profile\n",
    "\n",
    "from mapping_list_2 import to_upper_v1_to_list, to_upper_v2_to_list, to_upper_v3, to_upper_v4, prepare_data\n",
    "\n",
    "\n",
    "@profile\n",
    "def run_all():\n",
    "    data = prepare_data(24, 10000)\n",
    "    result1 = to_upper_v1_to_list(data)\n",
    "    result2 = to_upper_v2_to_list(data)\n",
    "    result3 = to_upper_v3(data)\n",
    "    result4 = to_upper_v4(data)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python mapping_list_memory_profiling_2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, получаем, что операция преобразования генератора в список \"съедает\" практически весь выигрыш от его \"ленивости\", и в целом он работает даже медленнее, чем list comprehension.\n",
    "\n",
    "В целом, выигрыш от функции map или генератора будет ощутим, если результаты его работы будут передаваться для дальнейшей обработки в виде итератора. При этом если в итоге будут обработаны все элементы списка, то мы получим лишь выигрыш по памяти, поскольку время на их обработку может оказаться даже больше, чем при использовании list comprehension (возможно, за счет дополнительных операций по созданию самого генератора и работы с элементами списка через него)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
